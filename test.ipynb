{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "Client key =  AIzaSyAlKLHe1eAmug6XeTlQ1DxzOsPI4zax7Ms \n",
      "Engine key =  006096712590953604068:qoxtr78cjow \n",
      "Query      =  per se \n",
      "Precision  =  10\n"
     ]
    }
   ],
   "source": [
    "# System imports\n",
    "import sys\n",
    "import argparse\n",
    "import pprint\n",
    "\n",
    "# API imports\n",
    "from googleapiclient.discovery import build\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "apikey, cseid = (\"AIzaSyAlKLHe1eAmug6XeTlQ1DxzOsPI4zax7Ms\", \"006096712590953604068:qoxtr78cjow\")\n",
    "precision, query = ('10', 'per se')\n",
    "\n",
    "print('\\nParameters:\\nClient key = ', apikey, '\\nEngine key = ', cseid,\n",
    "        '\\nQuery      = ', query, '\\nPrecision  = ', precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 67)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup search engine with above parameters\n",
    "service = build(\"customsearch\", \"v1\", developerKey=apikey)\n",
    "cse = service.cse().list(q=query, cx=cseid)\n",
    "\n",
    "# Run the query\n",
    "resdict = cse.execute()\n",
    "\n",
    "# For fast testing of 'per se' query\n",
    "relevant_items = [resdict['items'][0], resdict['items'][5],\n",
    "                  resdict['items'][6], resdict['items'][8],\n",
    "                  resdict['items'][9]]\n",
    "# Display search results and get relevance feedback lists\n",
    "#relevant_items, nonrelevant_items = get_rf_data(resdict)\n",
    "\n",
    "#print('\\nRelevant: {}\\tNonrelevant: {}\\n'.format(len(relevant_items),\n",
    "#        len(nonrelevant_items)))\n",
    "\n",
    "# Construct document-text list\n",
    "# TODO: try adding title text along with snippet's\n",
    "docs = [item['snippet'] for item in relevant_items]\n",
    "\n",
    "#Add query to docs to vectorize\n",
    "docs.append(query)\n",
    "\n",
    "# Read minimal stopword list from local file\n",
    "from pathlib import Path\n",
    "p = Path('.') / 'minimal-stop-pylist.txt'\n",
    "stopwords = eval(p.read_text())\n",
    "\n",
    "# Create CountVectorizer object anc construct doc-term matrix/index\n",
    "vectorizer = CountVectorizer(stop_words=stopwords)\n",
    "dtindex = vectorizer.fit_transform(docs)\n",
    "dtindex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtindex.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dtindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['oysters', 'vegetables', 'fish', 'salon', 'right', 'pastries',\n",
       "        'filled', 'meat', 'mini', 'left', 'chocolate', 'dipped', 'nut',\n",
       "        'macadamia', 'center', 'entrance', 'se', 'per'],\n",
       "       dtype='<U11'),\n",
       " array(['re', 'why', 'obvious', 'restaurants', 'worlds', 'many', 'dining',\n",
       "        'pleasure', 've', 'best', 'reviews', '1287', 'se', 'per'],\n",
       "       dtype='<U11'),\n",
       " array(['identity', 'restaurant', 'intentional', 'could', 'napkin', 'new',\n",
       "        'bring', 'failure', 'wondered', 'briefly', 'mystique', 'such',\n",
       "        '2016', '12', 'jan', 'se', 'per'],\n",
       "       dtype='<U11'),\n",
       " array(['city', 'york', 'manhattan', 'circle', 'columbus', '10', 'warner',\n",
       "        'time', 'floor', 'fourth', 'located', 'french', 'american',\n",
       "        'restaurant', 'new', 'center', 'se', 'per'],\n",
       "       dtype='<U11'),\n",
       " array(['table', 'find', 'size', 'party', 'date', 'select', 'ny',\n",
       "        'reservation', 'make', 'york', 'time', 'restaurant', 'new', 'se',\n",
       "        'per'],\n",
       "       dtype='<U11'),\n",
       " array(['se', 'per'],\n",
       "       dtype='<U11')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display nonzero terms in each document\n",
    "vectorizer.inverse_transform(dtindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 2, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 3, 1, 1, 0, 0, 1, 1, 0, 0, 3, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show doc-term sparse matrix\n",
    "dtindex.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10', '12', '1287', '2016', 'american', 'best', 'briefly', 'bring', 'center',\n",
      " 'chocolate', 'circle', 'city', 'columbus', 'could', 'date', 'dining', 'dipped',\n",
      " 'entrance', 'failure', 'filled', 'find', 'fish', 'floor', 'fourth', 'french',\n",
      " 'identity', 'intentional', 'jan', 'left', 'located', 'macadamia', 'make',\n",
      " 'manhattan', 'many', 'meat', 'mini', 'mystique', 'napkin', 'new', 'nut', 'ny',\n",
      " 'obvious', 'oysters', 'party', 'pastries', 'per', 'pleasure', 're',\n",
      " 'reservation', 'restaurant', 'restaurants', 'reviews', 'right', 'salon', 'se',\n",
      " 'select', 'size', 'such', 'table', 'time', 've', 'vegetables', 'warner', 'why',\n",
      " 'wondered', 'worlds', 'york']\n"
     ]
    }
   ],
   "source": [
    "# list the entire vocabulary \n",
    "terms = vectorizer.get_feature_names()\n",
    "pprint.pprint(terms, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doclen: 67, num terms: 67\n"
     ]
    }
   ],
   "source": [
    "# length of each doc in matrix should be same as length of feature list\n",
    "print('doclen: {}, num terms: {}'.format(len(dtindex.toarray()[0]), len(terms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('10', 0), ('12', 0), ('1287', 0), ('2016', 0), ('american', 0), ('best', 0),\n",
      " ('briefly', 0), ('bring', 0), ('center', 2), ('chocolate', 1), ('circle', 0),\n",
      " ('city', 0), ('columbus', 0), ('date', 0), ('dining', 0), ('dipped', 0),\n",
      " ('entrance', 1), ('failure', 1), ('filled', 0), ('fish', 1), ('floor', 0),\n",
      " ('fourth', 1), ('french', 0), ('identity', 0), ('intentional', 0), ('jan', 0),\n",
      " ('left', 0), ('located', 0), ('macadamia', 1), ('make', 0), ('manhattan', 1),\n",
      " ('meat', 0), ('mini', 0), ('mystique', 0), ('napkin', 1), ('new', 1),\n",
      " ('nut', 0), ('ny', 0), ('obvious', 0), ('oysters', 1), ('party', 0),\n",
      " ('pastries', 0), ('pleasure', 1), ('reservation', 0), ('restaurant', 1),\n",
      " ('restaurants', 2), ('reviews', 0), ('right', 0), ('salon', 0), ('se', 0),\n",
      " ('select', 0), ('size', 0), ('table', 2), ('time', 1), ('ve', 2),\n",
      " ('vegetables', 0), ('warner', 0), ('wondered', 0), ('worlds', 0), ('york', 0)]\n"
     ]
    }
   ],
   "source": [
    "# Create term-freq list\n",
    "termfreq = zip(count_vect_2.get_feature_names()[:60], dtindex.toarray()[0])\n",
    "pprint.pprint(list(termfreq), compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 5)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on paper example\n",
    "docs = [\"large dogs eat large dinners\", \"Dogs have mouths\", \"Large dinners for large mouths\"]\n",
    "query = 'large dogs'\n",
    "\n",
    "#Add query to docs to vectorize\n",
    "docs.append(query)\n",
    "\n",
    "# Create CountVectorizer object and construct doc-term matrix/index\n",
    "vectorizer = CountVectorizer(stop_words=stopwords)\n",
    "dtindex = vectorizer.fit_transform(docs)\n",
    "dtindex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dinners', 'dogs', 'eat', 'large', 'mouths']\n"
     ]
    }
   ],
   "source": [
    "terms = vectorizer.get_feature_names()\n",
    "pprint.pprint(terms, compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 0],\n",
       "       [0, 1, 0, 0, 1],\n",
       "       [1, 0, 0, 2, 1],\n",
       "       [0, 1, 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtindex.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 2, 0],\n",
       "       [0, 1, 0, 0, 1],\n",
       "       [1, 0, 0, 2, 1]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = dtindex[:3]\n",
    "dt.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 23 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = dt.transpose() * dt\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1, 1, 4, 1],\n",
       "       [1, 2, 1, 2, 1],\n",
       "       [1, 1, 1, 2, 0],\n",
       "       [4, 2, 2, 8, 2],\n",
       "       [1, 1, 0, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = dtindex[3]\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2 = t * q.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [ 4],\n",
       "       [ 3],\n",
       "       [10],\n",
       "       [ 3]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.51079322, -0.32467158],\n",
       "       [ 0.49204466,  1.30316641],\n",
       "       [ 2.27679545,  0.07640876]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD()\n",
    "x2 = svd.fit_transform(dtindex[:3])\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.51079322, -0.32467158, -0.76844374],\n",
       "       [ 0.49204466,  1.30316641, -0.24423219],\n",
       "       [ 2.27679545,  0.07640876,  0.90020229]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=3)\n",
    "x3 =svd.fit_transform(dtindex[:3])\n",
    "x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.51079322, -0.32467158, -0.76844374],\n",
       "       [ 0.49204466,  1.30316641, -0.24423219],\n",
       "       [ 2.27679545,  0.07640876,  0.90020229]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=4)\n",
    "x4 =svd.fit_transform(dtindex[:3])\n",
    "x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
